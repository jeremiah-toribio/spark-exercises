{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark sesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/26 13:54:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/26 13:54:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jmbp.localdomain:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14bfb5a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create enviroment\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "## 1. Read the cases, department, and source data into their own Spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql query\n",
    "url = env.get_db_url(env.user,env.password,env.host,'311_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql query\n",
    "cases_query = 'select * from cases limit 100000'\n",
    "dept_query = 'select * from dept'\n",
    "source_query = 'select * from source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas df\n",
    "cases_df = pd.read_sql(cases_query, url)\n",
    "dept_df = pd.read_sql(dept_query, url)\n",
    "source_df = pd.read_sql(source_query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark df\n",
    "cases = spark.createDataFrame(cases_df)\n",
    "dept = spark.createDataFrame(dept_df)\n",
    "source = spark.createDataFrame(source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/26 13:54:36 WARN TaskSetManager: Stage 0 contains a task of very large size (1656 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|num_days_late|case_closed|   dept_division|service_request_type|SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|       NO| -998.5087616|        YES|Field Operations|        Stray Animal|   999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's see how writing to the local disk works in Spark:\n",
    "\n",
    "    Write the code necessary to store the source data in both csv and json format.\n",
    "- Store these as sources_csv and sources_json.\n",
    "\n",
    "`Inspect your folder structure.`\n",
    "- What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------------+\n",
      "|index|source_id| source_username|\n",
      "+-----+---------+----------------+\n",
      "|    0|   100137|Merlene Blodgett|\n",
      "+-----+---------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CSV\n",
    "source.write.csv('data/source_csv',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON\n",
    "source.write.json('data/source_json',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Answer:\n",
    "# The files are saved in different instances and if using traditional pandas / python tools would require a different to tool to be able to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index', 'bigint'), ('source_id', 'string'), ('source_username', 'string')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + +\n",
      "Data types for DataFrame[index: bigint, source_id: string, source_username: string]:\n",
      "\n",
      "+-----+---------+----------------+\n",
      "|index|source_id| source_username|\n",
      "+-----+---------+----------------+\n",
      "|    0|   100137|Merlene Blodgett|\n",
      "+-----+---------+----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+ + + + + + + + + + + + + + + + +\n",
      "Data types for DataFrame[dept_division: string, dept_name: string, standardized_dept_name: string, dept_subject_to_SLA: int]:\n",
      "\n",
      "+---------------+----------------+----------------------+-------------------+\n",
      "|  dept_division|       dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+---------------+----------------+----------------------+-------------------+\n",
      "|311 Call Center|Customer Service|      Customer Service|               NULL|\n",
      "+---------------+----------------+----------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+ + + + + + + + + + + + + + + + +\n",
      "Data types for DataFrame[case_id: bigint, case_opened_date: string, case_closed_date: string, SLA_due_date: string, case_late: int, num_days_late: double, case_closed: int, dept_division: string, service_request_type: string, SLA_days: double, case_status: string, source_id: string, request_address: string, council_district: string]:\n",
      "\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|num_days_late|case_closed|   dept_division|service_request_type|SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|     NULL| -998.5087616|       NULL|Field Operations|        Stray Animal|   999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|             005|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/26 14:54:53 WARN TaskSetManager: Stage 19 contains a task of very large size (1656 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "dfs = [source,dept,cases]\n",
    "for df in dfs:\n",
    "    print(f'+ + + + + + + + + + + + + + + + +\\nData types for {df}:\\n')\n",
    "    df.dtypes\n",
    "    df.show(1)\n",
    "    #print('+ + + + + + + + + + + + + + + + +')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source is fine\n",
    "\n",
    "# dept could change 'dept_subject_to_SLA' as bool\n",
    "dept = dept.withColumn('dept_subject_to_SLA', (F.col('dept_subject_to_SLA') == 'YES').cast('int'))\n",
    "# cases could change anything with date as a date time rather than a string\n",
    "cases = cases.withColumns(\n",
    "{\n",
    "    'case_closed': (F.col('case_closed') == 'YES').cast('int'),\n",
    "    'case_late': (F.col('case_late') == 'YES').cast('int')\n",
    "})\n",
    "    # changing d type of council district\n",
    "cases = cases.withColumn(\n",
    "'council_district',\n",
    "F.format_string(\n",
    "    '%03d',\n",
    "    cases.council_district.cast('int')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploratory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How many Stray Animal cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert the council_district column to a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract the year from the case_closed_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Convert num_days_late from days to hours in a new column num_hours_late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Join the cases data with the source and department data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Are there any cases that do not have a request source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What are the top 10 service request types in terms of number of requests?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. What are the top 10 service request types in terms of average days late?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Does number of days late depend on department? (Answer without the use of a stats test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. How do number of days late depend on department and request type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
